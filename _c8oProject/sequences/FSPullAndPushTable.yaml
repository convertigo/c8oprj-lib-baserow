comment: Push a BaserowTable to FullSync for offline access
↓Call_Sequence [steps.SequenceStep-1670750961352]: 
  comment: Export table as CSV
  sourceSequence: lib_BaseRow.TableBulkExportToCSV
  ↓table_id [variables.StepVariable-1670750961354]: 
    comment: The table id to create and start an export job for
    description: table_id
    required: true
    value: 
↓IfExist [steps.IfExistStep-1672070253851]: 
  sourceDefinition: 
    - xmlizable: 
      - ↑classname: com.twinsoft.convertigo.beans.common.XMLVector
      - com.twinsoft.convertigo.beans.common.XMLVector: 
        - java.lang.String: 
          - ↑value: 1670750961352
        - java.lang.String: 
          - ↑value: ./document/error
  ↓Copy [steps.XMLCopyStep-1672070430752]: 
    sourceDefinition: 
      - xmlizable: 
        - ↑classname: com.twinsoft.convertigo.beans.common.XMLVector
        - com.twinsoft.convertigo.beans.common.XMLVector: 
          - java.lang.String: 
            - ↑value: 1670750961352
          - java.lang.String: 
            - ↑value: ./document/error
  ↓Return [steps.ReturnStep-1672070381257]: 
↓Call_Sequence1 [steps.SequenceStep-1670750973184]: 
  sourceSequence: lib_BaseRow.TableBulkExportWaitFInished
  ↓job_id [variables.StepVariable-1670750973186]: 
    comment: The job id to lookup information about.
    description: job_id
    required: true
    sourceDefinition: 
      - xmlizable: 
        - ↑classname: com.twinsoft.convertigo.beans.common.XMLVector
        - com.twinsoft.convertigo.beans.common.XMLVector: 
          - java.lang.String: 
            - ↑value: 1670750961352
          - java.lang.String: 
            - ↑value: ./document/id/text()
    value: 
↓jSimpleSource_1 [steps.SimpleSourceStep-1672070659482]: 
  sourceDefinition: 
    - xmlizable: 
      - ↑classname: com.twinsoft.convertigo.beans.common.XMLVector
      - com.twinsoft.convertigo.beans.common.XMLVector: 
        - java.lang.String: 
          - ↑value: 1670750973184
        - java.lang.String: 
          - ↑value: ./document/url
  variableName: assetURL
↓BuildAssetURL [steps.SimpleStep-1672070620012]: 
  comment: Compute URL with AWS extra  query parameters
  expression: |
    assetURL = assetURL.substring(0, assetURL.indexOf('?'));
    
↓jElement [steps.ElementStep-1672070801295]: 
  expression: assetURL
  nodeName: assetURL
↓Call_Transaction [steps.TransactionStep-1670751375718]: 
  comment: Download the exported data from Baserow
  sourceTransaction: lib_BaseRow.MediaConnector.Download_HTTP_transaction
  ↓__uri [variables.StepVariable-1670751375720]: 
    sourceDefinition: 
      - xmlizable: 
        - ↑classname: com.twinsoft.convertigo.beans.common.XMLVector
        - com.twinsoft.convertigo.beans.common.XMLVector: 
          - java.lang.String: 
            - ↑value: 1672070801295
          - java.lang.String: 
            - ↑value: ./text()
↓jSimpleSource [steps.SimpleSourceStep-1670751629546]: 
  sourceDefinition: 
    - xmlizable: 
      - ↑classname: com.twinsoft.convertigo.beans.common.XMLVector
      - com.twinsoft.convertigo.beans.common.XMLVector: 
        - java.lang.String: 
          - ↑value: 1670751375718
        - java.lang.String: 
          - ↑value: ./document/filepath/text()
  variableName: CSVPath
↓CreateCSVReader [steps.SimpleStep-1672073751160]: 
  expression: |
    '// Java Imports
    var Paths = java.nio.file.Paths;
    var Files = java.nio.file.Files;
    var CSVReaderBuilder = com.opencsv.CSVReaderBuilder;
    var CSVParserBuilder = com.opencsv.CSVParserBuilder;
    var RFC4180ParserBuilder = com.opencsv.RFC4180ParserBuilder;
    
    // init Params
    fileSeparator = ",";
    quoteChar = ''"'';
    
    // Log params
    log.debug("fileSeparator used will be: " + fileSeparator);
    log.debug("quoteChar used will be: " + quoteChar);
    
    // Declare global variables
    var br = null;
    var line = "";
    
    try{
    	// Get file path
    	var file = CSVPath;
    	
    	// Get file path
    	path = Paths.get(file);
    	log.debug("Path used will be: " + path);
    	
    	// Create a buffer reader
    	br = Files.newBufferedReader(path);
    	log.debug("Buffered reader created");
    	
    	// Instanciate CSVReaderBuilder, with RFC4180ParserBuilder (helping for special chars as \) 
    	var reader = new CSVReaderBuilder(br)
                    .withCSVParser(new RFC4180ParserBuilder()
                            .withQuoteChar(""+quoteChar)
                            .withSeparator(""+fileSeparator)
                            .build())
                    .build();
    	
    	log.debug("Builder is created");
    	
    	// read the first laine to get the column names...
    	firstLine = reader.readNext();
    }
    catch(e){
    	log.warn("An error occured " + JSON.stringify(e))
    }
    
    // Declare body var
    var body = {data: []};
    var cpt = 0;
    if(cptTotal == undefined){
    	var cptTotal = 0;
    }
    var last = false;'
↓jWhile [steps.WhileStep-1672074070887]: 
  condition: |
    'try {
        (line = reader.readNext())
    } catch (e) {
        log.warn("error reading" + JSON.stringify(e));
        reader.skip(1);
        line = line = reader.readNext();
    } line != null || last != true'
  ↓ComputeData [steps.SimpleStep-1672074070890]: 
    expression: |
      'if(line != null){
      	obj = {
      		"_id": "baserow_table_" + table_id + "_" + line[0]
      	};
      	firstLine.forEach((item, index) => {
      		if (index > 0)
      			obj[item] = line[index]
      	})
      	body.data.push(obj);
      	cpt++;
      }
      else{
      	last = true;
      }
      '
  ↓jIf [steps.IfStep-1672074070893]: 
    condition: cpt >= (+chunkSize) || last == true
    ↓stringifyBody [steps.SimpleStep-1672074070896]: 
      expression: |
        '// Copy and stringify body into a new var to be send to al subsequence
        var _use_json_base = "" + JSON.stringify(body.data);
        log.debug("Stringifying this line " + _use_json_base);
        
        cptTotal = cptTotal + (+(""+ cpt));
        log.warn("Actual total count is: " +cptTotal);
        
        // // Re init vars
        body ={data: []};
        cpt = 0;
        '
    ↓Call_Transaction_1 [steps.TransactionStep-1670758479150]: 
      sourceTransaction: lib_BaseRow.lib_baserow_fullsync.PostBulkDocuments
      ↓_use_json_base [variables.StepVariable-1672138076377]: 
        description: (string) – JSON use as a base for the array of documents (js array), or for individual documents (js object). Optional
↓table_id [variables.RequestableVariable-1670750989287]: 
  comment: The table id to create and start an export job for
  description: table_id
  required: true
↓TestOK [core.TestCase]: 
  ↓table_id [variables.TestCaseVariable-1670751187399]: 
    description: table_id
    required: true
    value: 418
  ↓chunkSize [variables.TestCaseVariable-1672134408819]: 
    description: table_id
    required: true
    value: 1024